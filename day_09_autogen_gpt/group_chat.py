"""```python\nimport autogen\nfrom autogen.agent import AssistantAgent, UserAgent\nfrom autogen.chat import GroupChat, GroupChatManager\nfrom autogen.agent.utils import config_list_from_json\n\n# Initialize Agents\ndef initialize_agents(config_list):\n    writer = AssistantAgent(\n        \"writer\",\n        llm_config={\"config_list\": config_list}\n    )\n\n    critic = AssistantAgent(\n        \"critic\",\n        llm_config={\"config_list\": config_list}\n    )\n\n    user = UserAgent(\n        \"user\",\n        llm_config={\"config_list\": config_list}\n    )\n\n    return writer, critic, user\n\n# Load LLM inference endpoints from an env variable or a file\nconfig_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")\n\n# Initialize agents\nwriter, critic, user = initialize_agents(config_list)\n\n# Create a group chat\ngroupchat = GroupChat(\n    agents=[user, writer, critic],\n    messages=[],\n    max_round=12,\n)\n\n# Create a group chat manager\nmanager = GroupChatManager(\n    groupchat=groupchat,\n    llm_config=config_list,\n)\n\n# Initiate a chat\nuser.initiate_chat(\n    manager,\n    message=\"What are the top 5 longest rivers in the world?\",\n)\n```"""